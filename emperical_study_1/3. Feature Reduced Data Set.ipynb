{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE REDUCED DATA SET: \n",
    "### Preprocessing a drastically reduced data set for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections:\n",
    "- <a href=\"#overview\">1. Overview of Dataset</a><br>\n",
    "- <a href=\"#missing\">2. Missing Values & Imputation</a><br>\n",
    "- <a href=\"#feature\">3. Feature Engineering</a><br>\n",
    "- <a href=\"#final\">4. Minimizing & Finalizing Feature Space</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"overview\"></a></p>\n",
    "## 1. Overview of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "df_train = pd.read_csv('./house-prices-advanced-regression-techniques/train.csv')\n",
    "df_test = pd.read_csv('./house-prices-advanced-regression-techniques/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['GrLivArea'] < 4500]\n",
    "df_train.shape\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated values\n",
    "print('Duplicated train values:', df_train.duplicated().sum())\n",
    "print('Duplicated test values:', df_test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge training and test Datasets for Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_id = df_train['Id']\n",
    "df_test_id = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID Column\n",
    "df_train = df_train.drop(columns=['Id'])\n",
    "df_test = df_test.drop(columns=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set variable to differnetiate between train and test\n",
    "df_train['section'] = \"Train\"\n",
    "df_test['section'] = \"Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sale Price column for df_test and set to 0 as a placeholder\n",
    "df_test['SalePrice'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the datasets\n",
    "df = pd.concat([df_train, df_test], ignore_index=True, axis = 0, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"missing\"></a></p>\n",
    "## 2. Missing Values & Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Columns with NA values\n",
    "missing = df.isnull().sum()\n",
    "\n",
    "# Vizualize missing value count\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar(figsize = (10,5))\n",
    "plt.xlabel('Feature',fontsize=15)\n",
    "plt.ylabel('Missing Count',fontsize = 15)\n",
    "plt.title('Missing Values by Feature', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Number of missing numerically\n",
    "print(missing)\n",
    "\n",
    "df[df['PoolArea'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Electrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Missing Electrical using Mode\n",
    "df['Electrical']=df['Electrical'].fillna(df['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Bsmt Baths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imput Mode for Missing Bsmt Bath Data\n",
    "df['BsmtHalfBath']=df['BsmtHalfBath'].fillna(df['BsmtHalfBath'].mode()[0])\n",
    "df['BsmtFullBath']=df['BsmtFullBath'].fillna(df['BsmtFullBath'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute for Garage Features for observations that have a garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcs\n",
    "fin_mode = df['GarageFinish'].mode()[0]\n",
    "qual_mode = df['GarageQual'].mode()[0]\n",
    "cond_mode = df['GarageCond'].mode()[0]\n",
    "\n",
    "# Impute where Garage Exists\n",
    "\n",
    "df['GarageCars']=df['GarageCars'].fillna(df['GarageCars'].mode()[0])\n",
    "\n",
    "df['GarageArea']=df['GarageArea'].fillna(df['GarageArea'].mean())\n",
    "\n",
    "df['GarageFinish']=np.where((df.GarageFinish.isna())&\\\n",
    "                          (df.GarageType.isna()==False),fin_mode,df['GarageFinish'])\n",
    "\n",
    "df['GarageQual']=np.where((df.GarageQual.isna())&\\\n",
    "                          (df.GarageType.isna()==False),qual_mode,df['GarageQual'])\n",
    "\n",
    "df['GarageCond']=np.where((df.GarageCond.isna())&\\\n",
    "                          (df.GarageType.isna()==False),cond_mode,df['GarageCond'])\n",
    "\n",
    "df['GarageYrBlt']=np.where((df.GarageYrBlt.isna())&\\\n",
    "                          (df.GarageType.isna()==False),df['YearBuilt'],df['GarageYrBlt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute MasVnrType for Houses with MasVnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnr_mode = df['MasVnrType'].mode()[0]\n",
    "\n",
    "df['MasVnrType']=np.where((df.MasVnrType.isna())&\\\n",
    "                          (df.MasVnrArea.isna()==False),vnr_mode,df['MasVnrType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Basement Variables for houses with a Bsmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_mode = df['BsmtQual'].mode()[0]\n",
    "\n",
    "df['BsmtQual'] = np.where((df.BsmtQual.isna())&\\\n",
    "                          (df.BsmtFinType1.isna()==False),qual_mode,df['BsmtQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_mode = df['BsmtCond'].mode()[0]\n",
    "\n",
    "df['BsmtCond'] = np.where((df.BsmtCond.isna())&\\\n",
    "                          (df.BsmtFinType1.isna()==False),cond_mode,df['BsmtCond'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Find mode of BsmtExposure\n",
    "bsmt_exposure_mode = df['BsmtExposure'].mode()[0]\n",
    "\n",
    "# Fill in for observation with basement\n",
    "df['BsmtExposure']=np.where((df.BsmtExposure.isna())&(df.BsmtQual.isna()==False),bsmt_exposure_mode,df['BsmtExposure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Find mode of BsmtFinType2\n",
    "bsmt2_exposure_mode = df['BsmtFinType2'].mode()[0]\n",
    "\n",
    "# Fill in for observation with basement\n",
    "df['BsmtFinType2']=np.where((df.BsmtFinType2.isna())&(df.BsmtQual.isna()==False),bsmt2_exposure_mode,df['BsmtFinType2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute PoolQC for houses with a Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find mode of PoolQC\n",
    "pool_mode = df['PoolQC'].mode()[0]\n",
    "\n",
    "# Fill in for observation with basement\n",
    "df['PoolQC']=np.where((df.PoolQC.isna())&(df.PoolArea > 0),pool_mode,df['PoolQC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute none for variables in which NA means None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of Columns to impute None for missing\n",
    "temp = ['PoolQC','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\"MasVnrType\",'GarageType','GarageFinish','GarageQual','GarageCond','FireplaceQu','Fence','MiscFeature','Alley']\n",
    "\n",
    "# Impute None\n",
    "df[temp] = df[temp].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute 0 for MasVnrArea and GarageYrBlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of Columns to impute 0 for missing\n",
    "temp2 = ['MasVnrArea','GarageYrBlt','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF']\n",
    "\n",
    "# Impute 0\n",
    "df[temp2] = df[temp2].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Mode for LotFrontage by Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Lot Frontage based on mean of neighborhood\n",
    "df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Utilities and Street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Utilities and Street as values are mostly all the same\n",
    "df = df.drop(columns=['Utilities','Street'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute for MSzoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSZoning']=df['MSZoning'].fillna(df['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ['Exterior1st','Exterior2nd','KitchenQual','SaleType','Functional']\n",
    "\n",
    "for col in temp:\n",
    "    df[col]=df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "print('Missing Values:',missing.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"feature\"></a></p>\n",
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MSSubClass to String since it is really categorical\n",
    "df['MSSubClass'] = df['MSSubClass'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal = df[['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond','ExterQual', 'ExterCond','HeatingQC',\\\n",
    "           'PoolQC', 'KitchenQual', 'BsmtFinType1','BsmtFinType2', 'GarageFinish', 'Functional',\\\n",
    "           'Fence','LandSlope','BsmtExposure','LotShape', 'PavedDrive','CentralAir']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of all ordinal values\n",
    "temp = {}\n",
    "\n",
    "for col in ordinal:\n",
    "    temp[col] = ordinal[col].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at Values\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict based on dict\n",
    "temp_dict = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5,'Mn': 2, 'Av': 3,'No': 1,\\\n",
    "             'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6,'RFn': 4, 'Fin': 6,\\\n",
    "             'Sal': 0, 'Sev': 1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2': 5, 'Min1': 6, 'Typ': 7,\\\n",
    "             'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4,'Sev': 0, 'Mod': 1, 'Gtl': 2,'Y':1,'N':0,\\\n",
    "             'Reg':3, 'IR1':2, 'IR2':1, 'IR3':0}\n",
    "\n",
    "# Convert Paved Drive on its own\n",
    "ordinal['PavedDrive'] = ordinal['PavedDrive'].map({'Y': 2, 'P': 1, 'N': 0}).astype(int)\n",
    "\n",
    "# Encode the rest of the columns\n",
    "for col in ordinal.columns.drop(\"PavedDrive\"):\n",
    "    ordinal[col] = ordinal[col].map(temp_dict).astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace columns in the train dataset\n",
    "for col in ordinal.columns:\n",
    "    df[col]=ordinal[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout remaining Categorical Columns\n",
    "df.columns[df.dtypes == object]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Partial Bsmt SF\n",
    "df = df.drop(columns=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Pool Area to Yes/No pool\n",
    "df['PoolArea'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else x)\n",
    "\n",
    "# Rename Column\n",
    "df=df.rename(columns = {'PoolArea':'Pool'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a total porch SF\n",
    "df['PorchSF'] = df['OpenPorchSF']+df['EnclosedPorch']+\\\n",
    "df['3SsnPorch']+df['ScreenPorch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn PorchTypes to Binary\n",
    "temp = ['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']\n",
    "\n",
    "for col in temp:\n",
    "    df[col] = df[col].apply(lambda x: 1 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all Numerical not in ordinal\n",
    "df.loc[:,((df.dtypes == int) | (df.dtypes == float))].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a total bath column\n",
    "df['TotalBath'] = df['BsmtFullBath']+(0.5*df['BsmtHalfBath'])+\\\n",
    "df['FullBath']+(0.5*df['HalfBath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a total Square Feet Column\n",
    "df['TotalSF'] = df['GrLivArea']+df['TotalBsmtSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Note: Possibly Consider Transforming Features that are Skewed)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"final\"></a></p>\n",
    "##  4. Minimizing & Finalizing Feature Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing .csv list of original features determined to be kept for analysis (including ones used above to calculate\n",
    "# new variables - that will be dropped before dummification):\n",
    "minFeatList = pd.read_csv('./house-prices-advanced-regression-techniques/reduced_variables.csv', header = None)\n",
    "minFeatList.columns = ['features']\n",
    "minFeatList = np.array(minFeatList.features.map(lambda x: x.replace(\"'\",\"\").strip()))\n",
    "\n",
    "# Pulling out array of original features:\n",
    "df_train_col = np.array(df_train.columns)\n",
    "df_col       = np.array(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating list of features to be removed from original list of features:\n",
    "delCol   = [df_train_col[i] for i in range(len(df_train_col)) if df_train_col[i] not in minFeatList]\n",
    "\n",
    "# Generating final list of features (prior to dummification):\n",
    "finalCol = [df_col[i] for i in range(len(df_col)) if df_col[i] not in delCol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[finalCol]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummify and Re-split Data for Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These features have already been used to generate new variables:\n",
    "df = df.drop(columns = ['GrLivArea','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch'])\n",
    "\n",
    "# Dummifying the remaining nominal categorical variables: \n",
    "df = pd.get_dummies(df,drop_first=True)\n",
    "\n",
    "# Sanity check:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the combined data set back to their train and test sets: \n",
    "train = df[df['section_Train'] == 1].drop(columns=['section_Train'])\n",
    "test  = df[df['section_Train'] == 0].drop(columns=['section_Train'])\n",
    "\n",
    "# Sanity check:\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check:\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Prep training  and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training feature set and training dependent set:\n",
    "X = train.drop(columns=['SalePrice'])\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check:\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test test by dropping 'placeholder' variable added above:\n",
    "XPredict = test.drop(columns=['SalePrice'])\n",
    "\n",
    "# Sanity check:\n",
    "XPredict.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing .csv(s) for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('./data/xtrain_red.csv')\n",
    "y.to_csv('./data/ytrain_red.csv')\n",
    "XPredict.to_csv('./data/xtest_red.csv')\n",
    "df_test_id.to_csv('./data/testID.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
